## Introduction
In recent years, scientists came to conclusion that Moore's Law, which states that density, therefore speed and complexity, of integrated circuits doubles every two years, is not valid anymore. Therefore the industry shifted its focus from enhancing speed to producing multicore and manycore processors. However, this was previously applied in graphics processing units as there data transforms could be done in batches and thus with slower clock speeds could keep the output framerate on a reliable level. Previously GPUs were used for image processing but in recent years there was an increased interest in different use cases for those. Convolutional neural networks, cryptographic functions, mass data processing can be done in parallel with multiple items at the same time. Thus different manufacturers such as NVidia, Apple, AMD, Intel designed interfaces, such as CUDA or OpenCL, to use conventional graphics cards as manycore processors. 